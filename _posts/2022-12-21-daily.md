---
layout: single
title:  "12/21"
categories : AITECH
tag : 
toc : true
---


# 할 일

- EASE 논문 읽기
- 베이스라인
- 한자
- MARG 모임

- 밤
	- 한자


# EASE
: Embarrassingly Shallow AutoEncoder

EASER : 반대방향 으로 적용한 EASE

SLIM(Sparse Linear Methods for Top-N Recommender Systems)과 굉장히 비슷한 모델이라고 한다.

Rec에서는 hidden layer 줄일 수록 더 성능 잘 나온다는 생각을 발전시켜 히든 레이어가 아예 없는 linear 모델을 만들었다. 

오토 인코더 처럼 binary input으로 넣는 방식이 성능이 좋아서 이를 선택했다고 함

기존 CF : 아이템끼리 유사도 행렬이 부정확한 방향으로 되어있음

-> EASE 에서는 hidden layer 


# 베이스라인 


유저 시퀀스

모델의 구성

1) init

아이템 encoder 가 핵심이다



2) 밑에가 pretrain 파생

3) Pretrain

4) Fine tune 부터 아래쪽은 train 용 코드 이다.


