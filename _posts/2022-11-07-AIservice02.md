---
layout: single
title:  "AI02 : Model Serving"
categories : AI_service
tag : 
toc : true
---

Serving : 모델을 앱/ 웹에 배포하는 과정, 모델 서비스화 하는 과정
Inference : 모델에 데이터가 제공되어 예측하는 경우, 사용하는 관점

+ Online Serving
+ Batch Serving
+ Edge Serving

# Online Serving
: 요청이 올 때마다 실시간으로 예측

ex) 기계 고장 예측 모델, 음식 배달 소요시간 예측

+ latency 를 최소화 하는 방법을 고려해야함 

	input 기반으로 database 데이터 추출해야하는 경우

	모델이 수행하는 연산이 무엇인지

+ 결과 값에 대한 보정 고려




## Web Server basic

client의 request -> 서버가 받음

모델 처리 -> server가 client 에게 respond

![image-20221107144207671](/images/2022-11-07-daily/image-20221107144207671.png)

## API
: Application Programming Interface

함수 잘 쓸 수 있게 정리해서 모아놓은거 (pytorch, tensorflow)

## 구현 방식

1) 직접 API 서버 개발
ex) Flask, FastAPI

2) 클라우드 서비스 활용
ex) SageMaker(AWS), Vertex AI(GCP)
단점) 다룰 줄 알아야 좋음, 비용문제

3) Serving 라이브러리 활용
ex) Tensorflow serving, torch serve, MLflow, BentoML

강의에서는 직접 개발을 해보면서 왜 이 방법을 선택하는지 알 수 있게 하는 능력을 기르겠다고 함.

# Batch Serving
: 주기적으로 학습을 하거나 예측을 하는 경우

함수 단위를 "주기적"으로 실행

ex) 
Apache Airflow



# Further Question

1.  [**Rules of Machine Learning:** **Best Practices for ML Engineering**](https://developers.google.com/machine-learning/guides/rules-of-ml) 문서 읽고 **정리하기!**

0) 머신러닝 전

+ 머신러닝, 없어도 된다!
+ 측정항목 설계, 구현!
+ 복잡한 휴리스틱 보단 머신러닝

(휴리스틱: 간편 추론)

1) 첫번째 파이프라인

+ 모델을 단순하게 유지, 인프라를 적절하게 유지
+ 머신러닝과는 별개로 인프라를 테스트
+ 과거 파이프라인을 복사할 때는 데이터 드롭에 주의
+ 휴리스틱을 특성으로 변환하거나 외부에서 처리 (전처리, 특성, 라벨 수정 등)

1-1) 모니터링

+ 시스템의 최신 요구사항 파악
+ 모델 서빙 전 문제 감지
+ silent failure(?) -> 데이터 추적, 수동으로 데이터 검사
+ 시스템 이나 데이터를 만든 사람을 틈틈히 기록

1-2) 첫번째 목표 설정

+ 어차피 수정되어야 하니까 최적화 항목 지나치게 고민 ㄴ
+ 간단하고 관찰 가능한 측정항목으로 선택
+ 해석 가능한 모델 -> 디버깅이 쉬워진다!

1)에서 end to end 시스템의 작동(시스템 테스트 포함)이 완료되면 2) 시작

2) 특성 추출

+ 출시와 반복을 계획
+ 학습된 특성이 아니라 직접 관찰 및 보고된 특성부터 시작.




2.  Online Serving / Batch Serving 기업들의 Use Case 찾아서 정리하기  
    (어떤 방식으로 되어 있는지 지금은 이해가 되지 않아도 문서를 천천히 읽고 정리하기)
