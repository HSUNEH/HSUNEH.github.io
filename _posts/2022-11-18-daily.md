---
layout: single
title:  "11/18 돌아온 쓰레기"
categories : AITECH, master
tag : 
toc : true
---


# 오늘의 목표

이 쓰레기는 2일을 날려먹어서 오늘 부터 빡세게 하려고한다.

일단 오늘 발표하기로한 10강 GNN-RS 공부하고

나머지 강의 쓱 끝내는 것을 목표로 한다.

집중력이 쓰레기가 된 나머지 아직도 유튜브에 손을 대는 모습을 보이는데..

과연 이 쓰레기의 하루는???


# 10강 GNN RS

+ GNN 의 효능
CTR 성능 올라감 / cold start 해소 / 다양한 추천 가능

## NGCF
: neural graph collaborative filtering

기존 모델에서의 user-item interaction 부족 문제를 해결하기 위해 등장한 녀석.

+ 1 hop layer

![image-20221118143450628](/images/2022-11-18-daily/image-20221118143450628.png)

nn.embedding으로 어찌 embedding 하고 

이를 message passing 하기 위해서 유저 임베딩과 아이템 임베딩이 hadamard product 되어 message를 생성하고 

이를 aggregation 하여 전달하는 구조

![image-20221118143906099](/images/2022-11-18-daily/image-20221118143906099.png)

이를 3번 반복하여 3단계 까지의 이웃을 보겠다는 모델

보통 (2~4 단계 까지만 쓴다고 함)

# LightGCN

feature transformation , non-linear activation function 둘 다 제거 -> 성능 올리고 효율도 올리고

마지막 Layer를 그대로 사용하면 over-smoothing (지나친 획일화) 문제가 생기기 때문에

Layer combination 진행 -> 문맥정보를 담고 있는 앞 layer 부터 디테일 정보를 담고 있는 뒷 layer 까지의 정보를 가져가려고 함


# UltraGCN

이후 나온 모델이 ultra gcn 인데 

![image-20221118150308214](/images/2022-11-18-daily/image-20221118150308214.png)
layer combination을 쓰지 않고 마지막 final embedding 값을 그냥 써서 어찌 계산 하겠다고 함

# GNN for Sequential recommendation

현재 사용되고 있는 방식은

![image-20221118150510519](/images/2022-11-18-daily/image-20221118150510519.png)

GNN으로 embedding 된 것들을 sequentail model을 통해 prediction을 뽑아내는 방식을 쓰고 있다고 함.