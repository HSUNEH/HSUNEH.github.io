---
layout: single
title:  "Context-aware Recommendation"
categories : RecSys
tag : 
toc : true
use_math : true
---

# Context-aware Recommendation
컨텍스트 기반 추천 시스템

->유저-아이템 상호작용 + 맥락적 정보(context)

![image-20221015190055413](/images/2022-10-15-RecSys8/image-20221015190055413.png)


## Click-Through Rate Prediction
CTR 예측 : 유저가 주어진 아이템을 클릭할 확률 (주로 광고에서 사용)

-> sigmoid 함수로 마지막에 처리

유저 Id 존재하지 않아도 다른 유저, context 정보로 처리

+ 이진 분류 문제 - Logistic Regression
![image-20221015190506223](/images/2022-10-15-RecSys8/image-20221015190506223.png)

Polynomial Model

![image-20221015190453279](/images/2022-10-15-RecSys8/image-20221015190453279.png)

+ 사용 데이터
Dense Feature : 비교적 공간 작은 벡터 

ex) 평점, 기온, 시간

Sparse Feature : 비교적 공간 넓은 벡터

ex) 요일, 분류, 키워드, id

One hot encoding을 하면 파라미터가 너무 많아질 수 있고, overfitting, underfitting 일어날 수 있으므로

Feature Embedding을 한 이후에 이 피쳐를 가지고 예측을 하기도 함



# FM(Factorization Machine)
SVM 과 Factorization model 의 장점을 결합함

SVM : 비선형 데이터셋에 대해 좋은 성능

MF : CF환경에서 좋은 성능 / 특별한 환경 혹은 데이터 에서만 적용 가능

![image-20221015213329585](/images/2022-10-15-RecSys8/image-20221015213329585.png)

![image-20221015213338224](/images/2022-10-15-RecSys8/image-20221015213338224.png)

앞에 두항은 Logistic regression,

세번째항은 polynomial 과 비슷하지만 $v_i , v_j$ 로 나뉘어 세부적으로 나타냄


## Sparse 데이터셋 예측하기
ex) 유저의 영화에 대한 평점 데이터

![image-20221015214341960](/images/2022-10-15-RecSys8/image-20221015214341960.png)

-> high sparsity data

유저 A의 ST에 대한 평점 예측

![image-20221015214711433](/images/2022-10-15-RecSys8/image-20221015214711433.png)


## 장점
+ vs SVM
sparse한 데이터에 대해 높은 예측 정보

선형 복잡도를 가지기 때문에 빠르게 학습

+ vs Matrix Facotization
유저, 아이템 id 이외에 다른 부가 정보들을 피쳐로 사용






# FFM(Field-aware Factorization Machine)
PITF 모델에서 아이디어를 얻어 FM을 변형하여 더 높은 성능을 보임.

+ PITF : (Pariwise Interaction Tensor Factorization)
user, item, tag 3개의 필드 클릭율 예측 위해 (user, item), (item, tag), (user, tag)서로에 대한 서로 다른 latent factor를 정의하여 구함


+ FFM
입력변수를 












# Gradient Boosting Machine(GBM)

