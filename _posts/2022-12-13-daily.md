---
layout: single
title:  "12/13 Movie 추천 2일차"
categories : AITECH
tag : 
toc : true
---
# 할 것

+ 2강
+ 3강
+ 4강
+ 미션2
+ 크로스핏
+ 주석달기

# 2강
모델, 메트릭 소개

## 모델

+ MF : 사용자와 아이템의 저차원 표현 학습. 

explicit data(-> RMSE), implicit data(-> 분류, 회귀) 모두 수행 가능

implicit data 다룰 때에는 WRMF(weight regularized MF), Weighted MF 사용

+ Bayesian Personalized Ranking
pairwise - ranking 문제를 형식화함.

personalized ranking function 을 추정한다.

최적화 하는 것이 AUC를 최적화 하는 것과 유사함.

- FPMC (Factorizing Personalized Markov Chains)
= MF + Markov Chain

사용자와 아이템 간의 관계, 아이템과 바로 이전 아이템 간의 관계를 함께 모델링함

![image-20221213125614835](/images/2022-12-13-daily/image-20221213125614835.png)

FPMC 함수를 BPR 프레임워크를 이용해서 최적화 하기도 함


+ PRME (Personalized Ranking Metric Embedding)
위의 함수들은 inner product(내적)을 이용한 계산을 했지만 여기서는 distance metric 을 이용하여 compatibility function을 나타냄

![image-20221213132121408](/images/2022-12-13-daily/image-20221213132121408.png)


## Evaluating

+ Rating
->explicit feedback

주로 Regression 으로 해결

metric : RMSE 사용

+ Top-K Ranking
->implicit feedback

regression, classification으로 풀어감

metric: Recall@K, NDCG@K, MRR 등으로 평가

## 참고 자료

+ 학회

![image-20221213133214675](/images/2022-12-13-daily/image-20221213133214675.png)

+ 라이브러리

![image-20221213133415596](/images/2022-12-13-daily/image-20221213133415596.png)

+ 데이터셋

https://cseweb.ucsd.edu/~jmcauley/datasets.html


# 3강 CF part1

+ Memory-based CF (neighborhood-based CF)

사용자-아이템 similarity 계산하여 rating predict / Top-k ranking

metric : Jaccard similarity(집합간 포함 관계), cosine similarity (벡터의 각거리), Pearson similiarity (각거리 에서 평균 빼서 계산)

예시) item-to-item CF in Amazon.com

![image-20221213135725809](/images/2022-12-13-daily/image-20221213135725809.png)

- Model-based CF

  - Latent Factor Models (MF)

  추천 시스템 뿐만 아니라 dimension reduction 테크닉으로 다양한 도메인에서 사용 가능

  ex) Netflix Prize

+ CF

![image-20221213143808571](/images/2022-12-13-daily/image-20221213143808571.png)

행렬이 주어지고 이를 채우는 matrix completion 문제로 볼 수 있음. 희소 행렬을 다루기 위한 추가적인 방법들이 필요하단 말씀

-> test/ train 이 명확히 나눠진게 아니라 칸이비워져 있는 task

![image-20221213145912004](/images/2022-12-13-daily/image-20221213145912004.png)

-> cold start problem 이 존재함 

+ User-free model
기존의 compatibility function에서 user term을 제거

![image-20221213150408493](/images/2022-12-13-daily/image-20221213150408493.png)

-> 새로운 사용자에 대해 추론 가능, cold start 대응 가능

+ SLIM(Sparse Linear Methods for top-n recsys)

user free 대표적인 모델

# 4강 딥러닝 기반 CF

![image-20221213152452592](/images/2022-12-13-daily/image-20221213152452592.png)

![image-20221213152542186](/images/2022-12-13-daily/image-20221213152542186.png)



기존 inner product를 대신하여 DNN을 사용하자!

## Autoencoder 기반 CF

rating prediction -> rating 값을 reconstruct

Top-K ranking -> interaction 발생 확률 reconstruct

![image-20221213152901992](/images/2022-12-13-daily/image-20221213152901992.png)




## Rating Prediction


+ U/I-RBM

![image-20221213153352432](/images/2022-12-13-daily/image-20221213153352432.png)

rating을 multi-class classification 문제로 변환했음

+ U/I-AutoRec

![image-20221213153552111](/images/2022-12-13-daily/image-20221213153552111.png)

I-autorec 이 u-autorec 보다 성능 좋았다고 함(데이터 특성상)

## Top-k Ranking

+ NeuMF

= element wise product(GMF) + concatenation (MLP)

linear 모델 표현력의 한계 극복하고자 함

![image-20221213182550013](/images/2022-12-13-daily/image-20221213182550013.png)

+ CDAE
  Collaborative denoising auto-encoders for top-n rec

  denoising auto encoder 사용

![image-20221213182735383](/images/2022-12-13-daily/image-20221213182735383.png)

- Multi VAE

  VAE를 interaction data의 reconstruction에 활용

![image-20221213223853538](/images/2022-12-13-daily/image-20221213223853538.png)

VAE를 학습하면서 KL annealing을 사용

(Regularization Term에 곱해지는 $\beta$ 값을 0에서 부터 선형적으로 증가하여 특정 값까지 올림-> 효율적인 학습 도모)



- 총정리 비교

![image-20221213224416178](/images/2022-12-13-daily/image-20221213224416178.png)

+ EASE
 Embarrasingly Shallow Autoencoders (당황스러울 정도로 얇은 AE)
 
 수식 형태가 User free 수식과 비슷함.

 hidden layer 필요로 하지 않아서 모델이 굉장히 단순하다(어이없을정도로)
 
 sparse한 데이터와 cold start problem에 강하다고 함(3기에서 좋은 성능을 보였다는 소문이)

+ SOTA of Movielens
 H+Vamp Gated, RecVAE

# 미션 2 Multi VAE

학습을 하면서 테스트 항목을 어떤 식으로 뽑았는지 알 수 있다 (아마 대회에서도 이런식으로 사용 했을 거 같다는 느낌)

설정해 놓은 테스트의 비율(0.2)만큼 랜덤으로 뽑아씀

train, valid, test 비율을 0.8, 0.1, 0.1 로 나눠서 했음

유저 순서도 전부 랜덤으로다가 섞어놔서 경향성의 문제는 생각 안해도 될듯하다.



